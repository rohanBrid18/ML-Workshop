{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralNetwork.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohanBrid18/ML-Workshop/blob/master/NeuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80iD0ZwD3-wj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68806337-35e8-4501-a384-f26536a209f5"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gym85Et74TsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dt4eIbt4WVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Dense(units=32, input_dim=20, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySPn-gXH45UI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Dense(units=20, activation='sigmoid'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PMyompy5GUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSAq4Ehs5t7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyhxpmKD6P6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.random.randint(100, size=(1000, 20))\n",
        "y = np.random.randint(2, size=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16vMI4rB6z47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRHdkmVW7BD8",
        "colab_type": "code",
        "outputId": "6df0c08e-008b-4a5b-bc5d-e8641043ee5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "model.fit(xtrain, ytrain, epochs=10)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0623 14:43:57.658849 139812631807872 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "750/750 [==============================] - 4s 6ms/step - loss: 0.7461 - acc: 0.5027\n",
            "Epoch 2/10\n",
            "750/750 [==============================] - 0s 99us/step - loss: 0.7159 - acc: 0.5027\n",
            "Epoch 3/10\n",
            "750/750 [==============================] - 0s 86us/step - loss: 0.7027 - acc: 0.5013\n",
            "Epoch 4/10\n",
            "750/750 [==============================] - 0s 87us/step - loss: 0.6981 - acc: 0.5053\n",
            "Epoch 5/10\n",
            "750/750 [==============================] - 0s 89us/step - loss: 0.6960 - acc: 0.4907\n",
            "Epoch 6/10\n",
            "750/750 [==============================] - 0s 97us/step - loss: 0.6950 - acc: 0.4840\n",
            "Epoch 7/10\n",
            "750/750 [==============================] - 0s 89us/step - loss: 0.6944 - acc: 0.4760\n",
            "Epoch 8/10\n",
            "750/750 [==============================] - 0s 89us/step - loss: 0.6940 - acc: 0.4773\n",
            "Epoch 9/10\n",
            "750/750 [==============================] - 0s 100us/step - loss: 0.6937 - acc: 0.4947\n",
            "Epoch 10/10\n",
            "750/750 [==============================] - 0s 97us/step - loss: 0.6935 - acc: 0.5027\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2857f97d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrC1-vRU8mv7",
        "colab_type": "code",
        "outputId": "5aa7e6d1-8edc-42fd-c35c-644355ac6f3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model.fit(xtrain, ytrain, epochs=10, batch_size=30)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "750/750 [==============================] - 0s 96us/step - loss: 0.6934 - acc: 0.5067\n",
            "Epoch 2/10\n",
            "750/750 [==============================] - 0s 92us/step - loss: 0.6931 - acc: 0.5120\n",
            "Epoch 3/10\n",
            "750/750 [==============================] - 0s 90us/step - loss: 0.6929 - acc: 0.5120\n",
            "Epoch 4/10\n",
            "750/750 [==============================] - 0s 93us/step - loss: 0.6925 - acc: 0.5053\n",
            "Epoch 5/10\n",
            "750/750 [==============================] - 0s 86us/step - loss: 0.6923 - acc: 0.5147\n",
            "Epoch 6/10\n",
            "750/750 [==============================] - 0s 90us/step - loss: 0.6922 - acc: 0.5133\n",
            "Epoch 7/10\n",
            "750/750 [==============================] - 0s 87us/step - loss: 0.6919 - acc: 0.5227\n",
            "Epoch 8/10\n",
            "750/750 [==============================] - 0s 98us/step - loss: 0.6917 - acc: 0.5200\n",
            "Epoch 9/10\n",
            "750/750 [==============================] - 0s 92us/step - loss: 0.6916 - acc: 0.5227\n",
            "Epoch 10/10\n",
            "750/750 [==============================] - 0s 103us/step - loss: 0.6913 - acc: 0.5067\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2857f4fe10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5UBQ7f29kNd",
        "colab_type": "code",
        "outputId": "c50d2464-bfde-4aa4-dfe4-ef7738cf7e8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3434
        }
      },
      "source": [
        "model.fit(xtrain, ytrain, epochs=100, batch_size=30)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "750/750 [==============================] - 0s 115us/step - loss: 0.6911 - acc: 0.5333\n",
            "Epoch 2/100\n",
            "750/750 [==============================] - 0s 94us/step - loss: 0.6911 - acc: 0.5227\n",
            "Epoch 3/100\n",
            "750/750 [==============================] - 0s 96us/step - loss: 0.6909 - acc: 0.5227\n",
            "Epoch 4/100\n",
            "750/750 [==============================] - 0s 111us/step - loss: 0.6905 - acc: 0.5253\n",
            "Epoch 5/100\n",
            "750/750 [==============================] - 0s 97us/step - loss: 0.6905 - acc: 0.5373\n",
            "Epoch 6/100\n",
            "750/750 [==============================] - 0s 93us/step - loss: 0.6904 - acc: 0.5253\n",
            "Epoch 7/100\n",
            "750/750 [==============================] - 0s 92us/step - loss: 0.6903 - acc: 0.5253\n",
            "Epoch 8/100\n",
            "750/750 [==============================] - 0s 89us/step - loss: 0.6899 - acc: 0.5373\n",
            "Epoch 9/100\n",
            "750/750 [==============================] - 0s 91us/step - loss: 0.6899 - acc: 0.5360\n",
            "Epoch 10/100\n",
            "750/750 [==============================] - 0s 91us/step - loss: 0.6896 - acc: 0.5453\n",
            "Epoch 11/100\n",
            "750/750 [==============================] - 0s 90us/step - loss: 0.6895 - acc: 0.5427\n",
            "Epoch 12/100\n",
            "750/750 [==============================] - 0s 88us/step - loss: 0.6895 - acc: 0.5387\n",
            "Epoch 13/100\n",
            "750/750 [==============================] - 0s 91us/step - loss: 0.6892 - acc: 0.5333\n",
            "Epoch 14/100\n",
            "750/750 [==============================] - 0s 94us/step - loss: 0.6891 - acc: 0.5533\n",
            "Epoch 15/100\n",
            "750/750 [==============================] - 0s 89us/step - loss: 0.6891 - acc: 0.5373\n",
            "Epoch 16/100\n",
            "750/750 [==============================] - 0s 93us/step - loss: 0.6891 - acc: 0.5427\n",
            "Epoch 17/100\n",
            "750/750 [==============================] - 0s 91us/step - loss: 0.6888 - acc: 0.5387\n",
            "Epoch 18/100\n",
            "750/750 [==============================] - 0s 94us/step - loss: 0.6885 - acc: 0.5600\n",
            "Epoch 19/100\n",
            "750/750 [==============================] - 0s 110us/step - loss: 0.6887 - acc: 0.5387\n",
            "Epoch 20/100\n",
            "750/750 [==============================] - 0s 95us/step - loss: 0.6885 - acc: 0.5440\n",
            "Epoch 21/100\n",
            "750/750 [==============================] - 0s 98us/step - loss: 0.6883 - acc: 0.5387\n",
            "Epoch 22/100\n",
            "750/750 [==============================] - 0s 93us/step - loss: 0.6882 - acc: 0.5547\n",
            "Epoch 23/100\n",
            "750/750 [==============================] - 0s 83us/step - loss: 0.6882 - acc: 0.5453\n",
            "Epoch 24/100\n",
            "750/750 [==============================] - 0s 94us/step - loss: 0.6879 - acc: 0.5547\n",
            "Epoch 25/100\n",
            "750/750 [==============================] - 0s 91us/step - loss: 0.6879 - acc: 0.5480\n",
            "Epoch 26/100\n",
            "750/750 [==============================] - 0s 90us/step - loss: 0.6877 - acc: 0.5467\n",
            "Epoch 27/100\n",
            "750/750 [==============================] - 0s 90us/step - loss: 0.6878 - acc: 0.5453\n",
            "Epoch 28/100\n",
            "750/750 [==============================] - 0s 90us/step - loss: 0.6876 - acc: 0.5507\n",
            "Epoch 29/100\n",
            "750/750 [==============================] - 0s 89us/step - loss: 0.6875 - acc: 0.5573\n",
            "Epoch 30/100\n",
            "750/750 [==============================] - 0s 94us/step - loss: 0.6872 - acc: 0.5560\n",
            "Epoch 31/100\n",
            "750/750 [==============================] - 0s 87us/step - loss: 0.6871 - acc: 0.5587\n",
            "Epoch 32/100\n",
            "750/750 [==============================] - 0s 90us/step - loss: 0.6872 - acc: 0.5547\n",
            "Epoch 33/100\n",
            "750/750 [==============================] - 0s 97us/step - loss: 0.6869 - acc: 0.5680\n",
            "Epoch 34/100\n",
            "750/750 [==============================] - 0s 99us/step - loss: 0.6871 - acc: 0.5507\n",
            "Epoch 35/100\n",
            "750/750 [==============================] - 0s 92us/step - loss: 0.6868 - acc: 0.5573\n",
            "Epoch 36/100\n",
            "750/750 [==============================] - 0s 100us/step - loss: 0.6866 - acc: 0.5613\n",
            "Epoch 37/100\n",
            "750/750 [==============================] - 0s 100us/step - loss: 0.6865 - acc: 0.5493\n",
            "Epoch 38/100\n",
            "750/750 [==============================] - 0s 93us/step - loss: 0.6864 - acc: 0.5507\n",
            "Epoch 39/100\n",
            "750/750 [==============================] - 0s 94us/step - loss: 0.6861 - acc: 0.5587\n",
            "Epoch 40/100\n",
            "750/750 [==============================] - 0s 90us/step - loss: 0.6861 - acc: 0.5680\n",
            "Epoch 41/100\n",
            "750/750 [==============================] - 0s 94us/step - loss: 0.6859 - acc: 0.5613\n",
            "Epoch 42/100\n",
            "750/750 [==============================] - 0s 107us/step - loss: 0.6859 - acc: 0.5613\n",
            "Epoch 43/100\n",
            "750/750 [==============================] - 0s 94us/step - loss: 0.6855 - acc: 0.5627\n",
            "Epoch 44/100\n",
            "750/750 [==============================] - 0s 92us/step - loss: 0.6856 - acc: 0.5627\n",
            "Epoch 45/100\n",
            "750/750 [==============================] - 0s 94us/step - loss: 0.6852 - acc: 0.5640\n",
            "Epoch 46/100\n",
            "750/750 [==============================] - 0s 94us/step - loss: 0.6851 - acc: 0.5680\n",
            "Epoch 47/100\n",
            "750/750 [==============================] - 0s 101us/step - loss: 0.6850 - acc: 0.5587\n",
            "Epoch 48/100\n",
            "750/750 [==============================] - 0s 103us/step - loss: 0.6850 - acc: 0.5613\n",
            "Epoch 49/100\n",
            "750/750 [==============================] - 0s 94us/step - loss: 0.6846 - acc: 0.5720\n",
            "Epoch 50/100\n",
            "750/750 [==============================] - 0s 100us/step - loss: 0.6846 - acc: 0.5707\n",
            "Epoch 51/100\n",
            "750/750 [==============================] - 0s 94us/step - loss: 0.6844 - acc: 0.5680\n",
            "Epoch 52/100\n",
            "750/750 [==============================] - 0s 92us/step - loss: 0.6844 - acc: 0.5773\n",
            "Epoch 53/100\n",
            "750/750 [==============================] - 0s 92us/step - loss: 0.6842 - acc: 0.5747\n",
            "Epoch 54/100\n",
            "750/750 [==============================] - 0s 92us/step - loss: 0.6840 - acc: 0.5733\n",
            "Epoch 55/100\n",
            "750/750 [==============================] - 0s 98us/step - loss: 0.6836 - acc: 0.5720\n",
            "Epoch 56/100\n",
            "750/750 [==============================] - 0s 96us/step - loss: 0.6837 - acc: 0.5733\n",
            "Epoch 57/100\n",
            "750/750 [==============================] - 0s 88us/step - loss: 0.6836 - acc: 0.5787\n",
            "Epoch 58/100\n",
            "750/750 [==============================] - 0s 97us/step - loss: 0.6832 - acc: 0.5827\n",
            "Epoch 59/100\n",
            "750/750 [==============================] - 0s 94us/step - loss: 0.6833 - acc: 0.5773\n",
            "Epoch 60/100\n",
            "750/750 [==============================] - 0s 90us/step - loss: 0.6829 - acc: 0.5787\n",
            "Epoch 61/100\n",
            "750/750 [==============================] - 0s 91us/step - loss: 0.6829 - acc: 0.5893\n",
            "Epoch 62/100\n",
            "750/750 [==============================] - 0s 116us/step - loss: 0.6826 - acc: 0.5853\n",
            "Epoch 63/100\n",
            "750/750 [==============================] - 0s 96us/step - loss: 0.6824 - acc: 0.5880\n",
            "Epoch 64/100\n",
            "750/750 [==============================] - 0s 91us/step - loss: 0.6823 - acc: 0.5947\n",
            "Epoch 65/100\n",
            "750/750 [==============================] - 0s 90us/step - loss: 0.6822 - acc: 0.5893\n",
            "Epoch 66/100\n",
            "750/750 [==============================] - 0s 91us/step - loss: 0.6820 - acc: 0.5867\n",
            "Epoch 67/100\n",
            "750/750 [==============================] - 0s 94us/step - loss: 0.6818 - acc: 0.5867\n",
            "Epoch 68/100\n",
            "750/750 [==============================] - 0s 96us/step - loss: 0.6816 - acc: 0.5867\n",
            "Epoch 69/100\n",
            "750/750 [==============================] - 0s 98us/step - loss: 0.6814 - acc: 0.5880\n",
            "Epoch 70/100\n",
            "750/750 [==============================] - 0s 93us/step - loss: 0.6812 - acc: 0.5947\n",
            "Epoch 71/100\n",
            "750/750 [==============================] - 0s 100us/step - loss: 0.6812 - acc: 0.5947\n",
            "Epoch 72/100\n",
            "750/750 [==============================] - 0s 94us/step - loss: 0.6808 - acc: 0.5933\n",
            "Epoch 73/100\n",
            "750/750 [==============================] - 0s 94us/step - loss: 0.6809 - acc: 0.5867\n",
            "Epoch 74/100\n",
            "750/750 [==============================] - 0s 97us/step - loss: 0.6805 - acc: 0.5840\n",
            "Epoch 75/100\n",
            "750/750 [==============================] - 0s 100us/step - loss: 0.6805 - acc: 0.6027\n",
            "Epoch 76/100\n",
            "750/750 [==============================] - 0s 119us/step - loss: 0.6804 - acc: 0.5853\n",
            "Epoch 77/100\n",
            "750/750 [==============================] - 0s 93us/step - loss: 0.6802 - acc: 0.5880\n",
            "Epoch 78/100\n",
            "750/750 [==============================] - 0s 93us/step - loss: 0.6798 - acc: 0.5960\n",
            "Epoch 79/100\n",
            "750/750 [==============================] - 0s 95us/step - loss: 0.6796 - acc: 0.6000\n",
            "Epoch 80/100\n",
            "750/750 [==============================] - 0s 94us/step - loss: 0.6795 - acc: 0.5853\n",
            "Epoch 81/100\n",
            "750/750 [==============================] - 0s 94us/step - loss: 0.6792 - acc: 0.5920\n",
            "Epoch 82/100\n",
            "750/750 [==============================] - 0s 93us/step - loss: 0.6791 - acc: 0.6053\n",
            "Epoch 83/100\n",
            "750/750 [==============================] - 0s 97us/step - loss: 0.6788 - acc: 0.5960\n",
            "Epoch 84/100\n",
            "750/750 [==============================] - 0s 93us/step - loss: 0.6785 - acc: 0.6067\n",
            "Epoch 85/100\n",
            "750/750 [==============================] - 0s 91us/step - loss: 0.6784 - acc: 0.6013\n",
            "Epoch 86/100\n",
            "750/750 [==============================] - 0s 94us/step - loss: 0.6781 - acc: 0.6067\n",
            "Epoch 87/100\n",
            "750/750 [==============================] - 0s 97us/step - loss: 0.6781 - acc: 0.6093\n",
            "Epoch 88/100\n",
            "750/750 [==============================] - 0s 92us/step - loss: 0.6778 - acc: 0.6107\n",
            "Epoch 89/100\n",
            "750/750 [==============================] - 0s 95us/step - loss: 0.6777 - acc: 0.6080\n",
            "Epoch 90/100\n",
            "750/750 [==============================] - 0s 137us/step - loss: 0.6773 - acc: 0.6053\n",
            "Epoch 91/100\n",
            "750/750 [==============================] - 0s 94us/step - loss: 0.6774 - acc: 0.6027\n",
            "Epoch 92/100\n",
            "750/750 [==============================] - 0s 91us/step - loss: 0.6771 - acc: 0.6027\n",
            "Epoch 93/100\n",
            "750/750 [==============================] - 0s 99us/step - loss: 0.6769 - acc: 0.6120\n",
            "Epoch 94/100\n",
            "750/750 [==============================] - 0s 99us/step - loss: 0.6765 - acc: 0.6067\n",
            "Epoch 95/100\n",
            "750/750 [==============================] - 0s 90us/step - loss: 0.6764 - acc: 0.6120\n",
            "Epoch 96/100\n",
            "750/750 [==============================] - 0s 92us/step - loss: 0.6764 - acc: 0.6160\n",
            "Epoch 97/100\n",
            "750/750 [==============================] - 0s 93us/step - loss: 0.6760 - acc: 0.6120\n",
            "Epoch 98/100\n",
            "750/750 [==============================] - 0s 98us/step - loss: 0.6759 - acc: 0.6200\n",
            "Epoch 99/100\n",
            "750/750 [==============================] - 0s 93us/step - loss: 0.6758 - acc: 0.6027\n",
            "Epoch 100/100\n",
            "750/750 [==============================] - 0s 94us/step - loss: 0.6756 - acc: 0.6093\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2857f6e0b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HcXBKIs94_S",
        "colab_type": "code",
        "outputId": "a9ef4834-7b2d-439a-91c1-ff42999cd171",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3434
        }
      },
      "source": [
        "model.fit(xtrain, ytrain, epochs=100, batch_size=75)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "750/750 [==============================] - 0s 47us/step - loss: 0.6750 - acc: 0.6107\n",
            "Epoch 2/100\n",
            "750/750 [==============================] - 0s 40us/step - loss: 0.6749 - acc: 0.6160\n",
            "Epoch 3/100\n",
            "750/750 [==============================] - 0s 38us/step - loss: 0.6749 - acc: 0.6227\n",
            "Epoch 4/100\n",
            "750/750 [==============================] - 0s 38us/step - loss: 0.6747 - acc: 0.6133\n",
            "Epoch 5/100\n",
            "750/750 [==============================] - 0s 39us/step - loss: 0.6747 - acc: 0.6133\n",
            "Epoch 6/100\n",
            "750/750 [==============================] - 0s 41us/step - loss: 0.6745 - acc: 0.6200\n",
            "Epoch 7/100\n",
            "750/750 [==============================] - 0s 38us/step - loss: 0.6745 - acc: 0.6147\n",
            "Epoch 8/100\n",
            "750/750 [==============================] - 0s 44us/step - loss: 0.6744 - acc: 0.6160\n",
            "Epoch 9/100\n",
            "750/750 [==============================] - 0s 42us/step - loss: 0.6744 - acc: 0.6160\n",
            "Epoch 10/100\n",
            "750/750 [==============================] - 0s 39us/step - loss: 0.6743 - acc: 0.6160\n",
            "Epoch 11/100\n",
            "750/750 [==============================] - 0s 38us/step - loss: 0.6742 - acc: 0.6160\n",
            "Epoch 12/100\n",
            "750/750 [==============================] - 0s 38us/step - loss: 0.6741 - acc: 0.6240\n",
            "Epoch 13/100\n",
            "750/750 [==============================] - 0s 38us/step - loss: 0.6743 - acc: 0.6253\n",
            "Epoch 14/100\n",
            "750/750 [==============================] - 0s 38us/step - loss: 0.6740 - acc: 0.6227\n",
            "Epoch 15/100\n",
            "750/750 [==============================] - 0s 38us/step - loss: 0.6739 - acc: 0.6173\n",
            "Epoch 16/100\n",
            "750/750 [==============================] - 0s 36us/step - loss: 0.6737 - acc: 0.6253\n",
            "Epoch 17/100\n",
            "750/750 [==============================] - 0s 40us/step - loss: 0.6738 - acc: 0.6200\n",
            "Epoch 18/100\n",
            "750/750 [==============================] - 0s 41us/step - loss: 0.6738 - acc: 0.6213\n",
            "Epoch 19/100\n",
            "750/750 [==============================] - 0s 41us/step - loss: 0.6737 - acc: 0.6200\n",
            "Epoch 20/100\n",
            "750/750 [==============================] - 0s 39us/step - loss: 0.6735 - acc: 0.6253\n",
            "Epoch 21/100\n",
            "750/750 [==============================] - 0s 39us/step - loss: 0.6734 - acc: 0.6160\n",
            "Epoch 22/100\n",
            "750/750 [==============================] - 0s 40us/step - loss: 0.6734 - acc: 0.6227\n",
            "Epoch 23/100\n",
            "750/750 [==============================] - 0s 41us/step - loss: 0.6733 - acc: 0.6213\n",
            "Epoch 24/100\n",
            "750/750 [==============================] - 0s 39us/step - loss: 0.6733 - acc: 0.6253\n",
            "Epoch 25/100\n",
            "750/750 [==============================] - 0s 40us/step - loss: 0.6732 - acc: 0.6293\n",
            "Epoch 26/100\n",
            "750/750 [==============================] - 0s 38us/step - loss: 0.6730 - acc: 0.6253\n",
            "Epoch 27/100\n",
            "750/750 [==============================] - 0s 40us/step - loss: 0.6730 - acc: 0.6267\n",
            "Epoch 28/100\n",
            "750/750 [==============================] - 0s 42us/step - loss: 0.6729 - acc: 0.6227\n",
            "Epoch 29/100\n",
            "750/750 [==============================] - 0s 42us/step - loss: 0.6729 - acc: 0.6253\n",
            "Epoch 30/100\n",
            "750/750 [==============================] - 0s 51us/step - loss: 0.6727 - acc: 0.6307\n",
            "Epoch 31/100\n",
            "750/750 [==============================] - 0s 40us/step - loss: 0.6726 - acc: 0.6240\n",
            "Epoch 32/100\n",
            "750/750 [==============================] - 0s 41us/step - loss: 0.6726 - acc: 0.6253\n",
            "Epoch 33/100\n",
            "750/750 [==============================] - 0s 41us/step - loss: 0.6725 - acc: 0.6213\n",
            "Epoch 34/100\n",
            "750/750 [==============================] - 0s 39us/step - loss: 0.6725 - acc: 0.6240\n",
            "Epoch 35/100\n",
            "750/750 [==============================] - 0s 38us/step - loss: 0.6725 - acc: 0.6267\n",
            "Epoch 36/100\n",
            "750/750 [==============================] - 0s 40us/step - loss: 0.6722 - acc: 0.6280\n",
            "Epoch 37/100\n",
            "750/750 [==============================] - 0s 43us/step - loss: 0.6720 - acc: 0.6240\n",
            "Epoch 38/100\n",
            "750/750 [==============================] - 0s 42us/step - loss: 0.6720 - acc: 0.6240\n",
            "Epoch 39/100\n",
            "750/750 [==============================] - 0s 42us/step - loss: 0.6723 - acc: 0.6267\n",
            "Epoch 40/100\n",
            "750/750 [==============================] - 0s 41us/step - loss: 0.6719 - acc: 0.6213\n",
            "Epoch 41/100\n",
            "750/750 [==============================] - 0s 43us/step - loss: 0.6718 - acc: 0.6293\n",
            "Epoch 42/100\n",
            "750/750 [==============================] - 0s 36us/step - loss: 0.6718 - acc: 0.6347\n",
            "Epoch 43/100\n",
            "750/750 [==============================] - 0s 37us/step - loss: 0.6719 - acc: 0.6280\n",
            "Epoch 44/100\n",
            "750/750 [==============================] - 0s 41us/step - loss: 0.6716 - acc: 0.6307\n",
            "Epoch 45/100\n",
            "750/750 [==============================] - 0s 44us/step - loss: 0.6715 - acc: 0.6320\n",
            "Epoch 46/100\n",
            "750/750 [==============================] - 0s 44us/step - loss: 0.6716 - acc: 0.6293\n",
            "Epoch 47/100\n",
            "750/750 [==============================] - 0s 41us/step - loss: 0.6714 - acc: 0.6227\n",
            "Epoch 48/100\n",
            "750/750 [==============================] - 0s 40us/step - loss: 0.6713 - acc: 0.6347\n",
            "Epoch 49/100\n",
            "750/750 [==============================] - 0s 42us/step - loss: 0.6711 - acc: 0.6347\n",
            "Epoch 50/100\n",
            "750/750 [==============================] - 0s 41us/step - loss: 0.6710 - acc: 0.6347\n",
            "Epoch 51/100\n",
            "750/750 [==============================] - 0s 39us/step - loss: 0.6710 - acc: 0.6333\n",
            "Epoch 52/100\n",
            "750/750 [==============================] - 0s 40us/step - loss: 0.6709 - acc: 0.6333\n",
            "Epoch 53/100\n",
            "750/750 [==============================] - 0s 39us/step - loss: 0.6709 - acc: 0.6333\n",
            "Epoch 54/100\n",
            "750/750 [==============================] - 0s 38us/step - loss: 0.6707 - acc: 0.6347\n",
            "Epoch 55/100\n",
            "750/750 [==============================] - 0s 38us/step - loss: 0.6709 - acc: 0.6347\n",
            "Epoch 56/100\n",
            "750/750 [==============================] - 0s 39us/step - loss: 0.6708 - acc: 0.6320\n",
            "Epoch 57/100\n",
            "750/750 [==============================] - 0s 40us/step - loss: 0.6706 - acc: 0.6360\n",
            "Epoch 58/100\n",
            "750/750 [==============================] - 0s 42us/step - loss: 0.6705 - acc: 0.6320\n",
            "Epoch 59/100\n",
            "750/750 [==============================] - 0s 37us/step - loss: 0.6704 - acc: 0.6333\n",
            "Epoch 60/100\n",
            "750/750 [==============================] - 0s 38us/step - loss: 0.6704 - acc: 0.6360\n",
            "Epoch 61/100\n",
            "750/750 [==============================] - 0s 41us/step - loss: 0.6704 - acc: 0.6373\n",
            "Epoch 62/100\n",
            "750/750 [==============================] - 0s 49us/step - loss: 0.6702 - acc: 0.6333\n",
            "Epoch 63/100\n",
            "750/750 [==============================] - 0s 43us/step - loss: 0.6702 - acc: 0.6307\n",
            "Epoch 64/100\n",
            "750/750 [==============================] - 0s 43us/step - loss: 0.6700 - acc: 0.6360\n",
            "Epoch 65/100\n",
            "750/750 [==============================] - 0s 45us/step - loss: 0.6700 - acc: 0.6360\n",
            "Epoch 66/100\n",
            "750/750 [==============================] - 0s 46us/step - loss: 0.6699 - acc: 0.6440\n",
            "Epoch 67/100\n",
            "750/750 [==============================] - 0s 39us/step - loss: 0.6698 - acc: 0.6333\n",
            "Epoch 68/100\n",
            "750/750 [==============================] - 0s 39us/step - loss: 0.6697 - acc: 0.6347\n",
            "Epoch 69/100\n",
            "750/750 [==============================] - 0s 42us/step - loss: 0.6696 - acc: 0.6387\n",
            "Epoch 70/100\n",
            "750/750 [==============================] - 0s 44us/step - loss: 0.6695 - acc: 0.6387\n",
            "Epoch 71/100\n",
            "750/750 [==============================] - 0s 41us/step - loss: 0.6694 - acc: 0.6400\n",
            "Epoch 72/100\n",
            "750/750 [==============================] - 0s 40us/step - loss: 0.6694 - acc: 0.6413\n",
            "Epoch 73/100\n",
            "750/750 [==============================] - 0s 40us/step - loss: 0.6693 - acc: 0.6333\n",
            "Epoch 74/100\n",
            "750/750 [==============================] - 0s 38us/step - loss: 0.6691 - acc: 0.6427\n",
            "Epoch 75/100\n",
            "750/750 [==============================] - 0s 40us/step - loss: 0.6690 - acc: 0.6360\n",
            "Epoch 76/100\n",
            "750/750 [==============================] - 0s 41us/step - loss: 0.6690 - acc: 0.6360\n",
            "Epoch 77/100\n",
            "750/750 [==============================] - 0s 40us/step - loss: 0.6689 - acc: 0.6373\n",
            "Epoch 78/100\n",
            "750/750 [==============================] - 0s 42us/step - loss: 0.6688 - acc: 0.6413\n",
            "Epoch 79/100\n",
            "750/750 [==============================] - 0s 41us/step - loss: 0.6689 - acc: 0.6373\n",
            "Epoch 80/100\n",
            "750/750 [==============================] - 0s 42us/step - loss: 0.6686 - acc: 0.6387\n",
            "Epoch 81/100\n",
            "750/750 [==============================] - 0s 40us/step - loss: 0.6686 - acc: 0.6400\n",
            "Epoch 82/100\n",
            "750/750 [==============================] - 0s 42us/step - loss: 0.6685 - acc: 0.6387\n",
            "Epoch 83/100\n",
            "750/750 [==============================] - 0s 40us/step - loss: 0.6685 - acc: 0.6427\n",
            "Epoch 84/100\n",
            "750/750 [==============================] - 0s 43us/step - loss: 0.6683 - acc: 0.6360\n",
            "Epoch 85/100\n",
            "750/750 [==============================] - 0s 43us/step - loss: 0.6683 - acc: 0.6413\n",
            "Epoch 86/100\n",
            "750/750 [==============================] - 0s 47us/step - loss: 0.6683 - acc: 0.6413\n",
            "Epoch 87/100\n",
            "750/750 [==============================] - 0s 42us/step - loss: 0.6681 - acc: 0.6440\n",
            "Epoch 88/100\n",
            "750/750 [==============================] - 0s 57us/step - loss: 0.6680 - acc: 0.6427\n",
            "Epoch 89/100\n",
            "750/750 [==============================] - 0s 42us/step - loss: 0.6680 - acc: 0.6400\n",
            "Epoch 90/100\n",
            "750/750 [==============================] - 0s 39us/step - loss: 0.6677 - acc: 0.6400\n",
            "Epoch 91/100\n",
            "750/750 [==============================] - 0s 41us/step - loss: 0.6677 - acc: 0.6427\n",
            "Epoch 92/100\n",
            "750/750 [==============================] - 0s 39us/step - loss: 0.6676 - acc: 0.6413\n",
            "Epoch 93/100\n",
            "750/750 [==============================] - 0s 43us/step - loss: 0.6675 - acc: 0.6427\n",
            "Epoch 94/100\n",
            "750/750 [==============================] - 0s 55us/step - loss: 0.6674 - acc: 0.6467\n",
            "Epoch 95/100\n",
            "750/750 [==============================] - 0s 40us/step - loss: 0.6673 - acc: 0.6440\n",
            "Epoch 96/100\n",
            "750/750 [==============================] - 0s 39us/step - loss: 0.6674 - acc: 0.6400\n",
            "Epoch 97/100\n",
            "750/750 [==============================] - 0s 40us/step - loss: 0.6672 - acc: 0.6507\n",
            "Epoch 98/100\n",
            "750/750 [==============================] - 0s 41us/step - loss: 0.6671 - acc: 0.6453\n",
            "Epoch 99/100\n",
            "750/750 [==============================] - 0s 42us/step - loss: 0.6670 - acc: 0.6453\n",
            "Epoch 100/100\n",
            "750/750 [==============================] - 0s 42us/step - loss: 0.6669 - acc: 0.6480\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2857f4f3c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtihVsb6-MLw",
        "colab_type": "code",
        "outputId": "5f8a0316-2ef3-40bd-9533-cd91409c428d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6545
        }
      },
      "source": [
        "model.get_weights()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-1.54481485e-01, -1.78636611e-01,  2.86364019e-01,\n",
              "         -2.46324793e-01, -2.34804735e-01, -2.37815157e-01,\n",
              "          1.10525608e-01,  2.56594121e-01,  3.42338651e-01,\n",
              "          1.19042307e-01,  2.94785388e-02,  2.15880975e-01,\n",
              "         -1.42931312e-01,  6.61626458e-03,  7.97670037e-02,\n",
              "          3.97970341e-02, -1.13114312e-01,  2.87625939e-01,\n",
              "          1.09096229e-01, -2.82556206e-01, -1.84392825e-01,\n",
              "         -5.72666638e-02,  2.10173786e-01,  3.10906112e-01,\n",
              "          5.25489189e-02, -1.24274788e-03,  7.15797469e-02,\n",
              "         -2.71670580e-01, -2.16119334e-01,  1.38477802e-01,\n",
              "         -2.66729325e-01, -1.91355482e-01],\n",
              "        [ 1.05013669e-01, -5.83277121e-02,  2.25534186e-01,\n",
              "          1.86645135e-01,  2.46002287e-01,  1.44852504e-01,\n",
              "         -1.45208538e-01,  2.78739452e-01,  2.49681041e-01,\n",
              "         -8.87321979e-02,  2.85319109e-02,  2.82655418e-01,\n",
              "          1.66104853e-01, -2.10480671e-02, -2.78570503e-01,\n",
              "          6.24837615e-02,  2.84917831e-01,  3.26345384e-01,\n",
              "         -2.19868585e-01, -2.51897871e-01, -3.04687142e-01,\n",
              "         -1.09306432e-01,  2.42166802e-01,  1.95962533e-01,\n",
              "         -9.19880643e-02, -1.56178628e-03, -3.16863418e-01,\n",
              "         -2.52025221e-02, -1.70637190e-01, -1.62958577e-01,\n",
              "          2.95763370e-02,  8.65596533e-02],\n",
              "        [ 3.33599567e-01,  2.66727090e-01,  3.13460175e-03,\n",
              "         -1.71448916e-01,  2.69884914e-01,  3.29662979e-01,\n",
              "          2.68999487e-01,  1.62276164e-01,  2.80830145e-01,\n",
              "         -1.56295642e-01,  3.84992138e-02,  2.73266703e-01,\n",
              "         -3.50593388e-01,  1.10463299e-01,  2.93498218e-01,\n",
              "         -3.07391822e-01,  4.05802950e-02, -2.06323415e-01,\n",
              "          4.28025685e-02, -2.65440136e-01,  1.14650093e-01,\n",
              "          2.43757322e-01, -3.07829708e-01, -2.55044103e-01,\n",
              "         -2.00210810e-01,  1.91484869e-01,  5.60787469e-02,\n",
              "         -3.36548835e-01, -1.53125986e-01,  3.07928771e-01,\n",
              "         -1.46294548e-03, -1.89849466e-01],\n",
              "        [-1.60393476e-01, -3.46160054e-01, -2.27157414e-01,\n",
              "         -1.57310098e-01, -1.18817888e-01, -1.68318257e-01,\n",
              "         -3.25325519e-01, -6.01882720e-03, -2.26132825e-01,\n",
              "          1.55692324e-01,  6.69658780e-02,  3.10415119e-01,\n",
              "          8.13220516e-02, -2.21535042e-01,  4.68963161e-02,\n",
              "         -8.04424137e-02, -5.10224998e-02,  1.31535321e-01,\n",
              "          1.88270643e-01, -9.47033614e-02,  1.02012709e-01,\n",
              "          2.04864621e-01, -2.98410952e-01, -1.13064967e-01,\n",
              "         -2.35085245e-02,  8.90099273e-06,  1.32799551e-01,\n",
              "         -1.00484580e-01, -1.99597672e-01, -8.64726603e-02,\n",
              "          2.32284088e-02,  4.42111492e-01],\n",
              "        [-3.11423212e-01,  1.23603508e-01,  1.04016080e-01,\n",
              "         -3.38219672e-01,  1.07811004e-01, -6.78268895e-02,\n",
              "         -2.34539621e-02,  3.11664551e-01,  1.14783511e-01,\n",
              "         -3.02317441e-01, -2.53668666e-01, -1.35082319e-01,\n",
              "          2.13368684e-01,  2.60688663e-01, -1.22057535e-01,\n",
              "         -1.33317098e-01,  6.89600557e-02,  2.83647597e-01,\n",
              "         -2.89133012e-01,  6.41732588e-02,  3.28531623e-01,\n",
              "         -2.95641124e-01, -3.53265792e-01, -4.58889501e-03,\n",
              "          1.80767342e-01,  2.64041245e-01,  5.68832867e-02,\n",
              "         -6.35692850e-03, -1.01295009e-01,  9.79299247e-02,\n",
              "          5.10132015e-02, -2.69846410e-01],\n",
              "        [-3.12162250e-01,  5.10335974e-02, -7.62965605e-02,\n",
              "          4.98745069e-02, -2.72184312e-01, -1.08950667e-01,\n",
              "         -2.74077863e-01, -1.73507079e-01,  7.85767287e-02,\n",
              "         -1.97818186e-02,  1.19595863e-01, -1.89549103e-01,\n",
              "          6.16501831e-02, -1.03711970e-01,  2.77270913e-01,\n",
              "          1.88856453e-01,  2.87725002e-01, -2.02930391e-01,\n",
              "         -2.63953046e-03,  6.24895766e-02,  6.67856485e-02,\n",
              "         -3.29736739e-01,  2.54316062e-01, -1.04411535e-01,\n",
              "          3.16911726e-03, -5.05113937e-02,  1.08529210e-01,\n",
              "         -2.18168303e-01,  1.23489052e-01, -2.84982055e-01,\n",
              "          1.15495501e-02, -1.77137271e-01],\n",
              "        [-5.14563695e-02, -1.38999507e-01,  1.08351950e-02,\n",
              "         -1.52155295e-01,  6.39254078e-02, -2.58250177e-01,\n",
              "         -3.30499917e-01,  2.71509171e-01,  2.42672190e-01,\n",
              "          1.78534225e-01,  2.09936872e-01,  3.27464938e-01,\n",
              "          2.57089913e-01,  3.93312424e-02, -2.79484019e-02,\n",
              "          2.21473172e-01, -2.65067488e-01, -3.14375132e-01,\n",
              "          7.97349885e-02, -1.73235610e-02, -2.66075563e-02,\n",
              "          3.24677192e-02, -5.65845445e-02, -2.50527650e-01,\n",
              "          1.73304543e-01,  1.70341134e-01, -2.83567220e-01,\n",
              "         -6.44463599e-02, -2.07931206e-01,  2.86907136e-01,\n",
              "          6.93208054e-02, -2.91503757e-01],\n",
              "        [-2.57364422e-01,  1.55256316e-01, -4.05930029e-03,\n",
              "          2.36320123e-01, -3.16112757e-01,  2.26675849e-02,\n",
              "         -1.89879745e-01,  2.92737335e-01,  3.04133981e-01,\n",
              "          1.25765398e-01, -1.01124890e-01,  1.14773490e-01,\n",
              "         -2.47885570e-01,  1.68918982e-01,  1.91721469e-01,\n",
              "          5.48192039e-02, -3.09446156e-01,  1.57607615e-01,\n",
              "         -2.47852385e-01,  2.36060068e-01,  3.41946743e-02,\n",
              "         -1.68096349e-01, -5.53175174e-02,  2.16972455e-01,\n",
              "          1.33758187e-01,  1.38508314e-02,  2.72955865e-01,\n",
              "         -9.73159671e-02, -2.85227686e-01,  1.12886764e-01,\n",
              "         -1.53547886e-03,  2.72669066e-02],\n",
              "        [ 2.94255801e-02,  5.51338168e-03,  2.28100210e-01,\n",
              "          2.26530239e-01, -1.91260234e-01,  1.99765816e-01,\n",
              "         -2.23224550e-01,  3.40046197e-01,  2.24196911e-01,\n",
              "          1.40798762e-01,  1.12692662e-01,  2.26265386e-01,\n",
              "         -1.92681011e-02,  1.88498795e-01,  2.12699726e-01,\n",
              "         -1.47883549e-01,  1.27194831e-02, -9.22776312e-02,\n",
              "          3.88246059e-01, -1.32961854e-01,  2.11346194e-01,\n",
              "         -6.30353391e-02, -3.69161926e-02,  2.16251329e-01,\n",
              "          2.56085515e-01, -2.03808993e-01, -2.79653698e-01,\n",
              "         -2.79019892e-01, -1.64520800e-01,  1.43668652e-01,\n",
              "         -1.83499798e-01,  1.90828323e-01],\n",
              "        [ 9.98607352e-02,  2.44197741e-01,  2.31078997e-01,\n",
              "          2.40049183e-01,  2.44591385e-02, -1.30530193e-01,\n",
              "         -1.23448610e-01, -1.43616334e-01,  3.21988583e-01,\n",
              "         -9.72343385e-02,  1.99710146e-01, -1.26274884e-01,\n",
              "         -2.58484960e-01,  4.51880842e-02, -6.05185516e-02,\n",
              "          4.20720950e-02,  9.88898203e-02, -1.69489652e-01,\n",
              "          2.08508417e-01,  7.71838948e-02,  2.06844866e-01,\n",
              "          2.40570635e-01,  2.67310530e-01, -1.83620811e-01,\n",
              "         -1.80863038e-01, -4.85391766e-02, -2.72486717e-01,\n",
              "          2.61003911e-01,  2.08094686e-01,  1.84595108e-01,\n",
              "         -5.32957055e-02,  1.18645383e-02],\n",
              "        [-5.87072149e-02,  3.16298485e-01,  3.32069784e-01,\n",
              "         -3.30805063e-01,  2.13386118e-01, -3.54301095e-01,\n",
              "          1.01379812e-01, -2.63759699e-02,  2.44362444e-01,\n",
              "         -7.62705877e-02, -2.75795370e-01, -4.34022248e-02,\n",
              "         -1.64327145e-01, -1.52992338e-01,  1.83515728e-01,\n",
              "         -4.08395519e-03,  2.53962129e-01,  7.34380782e-02,\n",
              "         -5.97090647e-02,  1.61844715e-01,  2.36824527e-01,\n",
              "         -3.30279350e-01,  2.47366846e-01, -2.05637634e-01,\n",
              "         -4.86357771e-02,  2.05061406e-01,  1.26814097e-01,\n",
              "         -1.60232320e-01, -6.62048534e-02,  2.17941880e-01,\n",
              "         -2.74702072e-01,  2.03302547e-01],\n",
              "        [ 1.07112944e-01,  2.33773082e-01, -3.69074829e-02,\n",
              "         -2.69546837e-01, -1.26181498e-01, -1.29634952e-02,\n",
              "          1.62506372e-01, -3.15731972e-01,  7.89749771e-02,\n",
              "         -3.29088926e-01,  2.96638966e-01,  2.24352509e-01,\n",
              "          4.44837920e-02, -1.95853025e-01, -7.82630295e-02,\n",
              "          1.74251691e-01,  9.63830575e-02,  3.14583600e-01,\n",
              "          1.85702056e-01, -7.34728649e-02, -1.93530649e-01,\n",
              "         -3.19193184e-01, -2.79535949e-01,  3.20623606e-01,\n",
              "          1.71235755e-01,  2.30861902e-02,  4.75307442e-02,\n",
              "          2.20946729e-01,  1.23857215e-01,  2.85565495e-01,\n",
              "         -3.52230132e-01, -9.07951221e-02],\n",
              "        [-1.73718080e-01, -2.39128336e-01, -2.17088282e-01,\n",
              "          2.68391430e-01, -1.17905393e-01, -3.49712861e-03,\n",
              "          7.34956414e-02, -9.39569622e-02, -3.11131597e-01,\n",
              "         -3.39053452e-01, -1.69236615e-01, -2.63488740e-01,\n",
              "          1.91322744e-01,  1.28279865e-01,  3.08303177e-01,\n",
              "          7.82889500e-02, -2.67656475e-01,  1.08962715e-01,\n",
              "         -1.81058601e-01, -1.45705149e-01,  4.81282175e-02,\n",
              "         -3.25572193e-01,  2.90752381e-01,  2.12129336e-02,\n",
              "          1.53646588e-01,  9.53956842e-02,  2.89275404e-03,\n",
              "         -2.12563932e-01,  2.83527851e-01,  2.81284302e-01,\n",
              "          1.41720518e-01, -2.90818363e-01],\n",
              "        [-1.52098298e-01,  1.84759513e-01, -8.41550305e-02,\n",
              "         -2.92519871e-02, -2.37437353e-01, -2.72354871e-01,\n",
              "         -8.27292278e-02, -2.65142560e-01, -1.96345076e-01,\n",
              "          1.54018909e-01, -2.33873799e-01,  3.39440644e-01,\n",
              "         -3.57659012e-02,  1.68875560e-01, -1.95105374e-01,\n",
              "         -1.37630194e-01,  1.64797634e-01,  2.79268511e-02,\n",
              "          2.19831504e-02, -2.72064656e-01,  1.56586856e-01,\n",
              "         -7.92605653e-02, -3.84130441e-02,  2.85731882e-01,\n",
              "         -1.31042954e-02,  1.98283449e-01,  2.87554324e-01,\n",
              "         -5.80036044e-02,  9.98592004e-02, -2.04118326e-01,\n",
              "          2.58471817e-01,  6.99075451e-03],\n",
              "        [-1.12911656e-01, -2.00084388e-01,  6.79323003e-02,\n",
              "         -1.08806016e-02,  4.50242981e-02, -3.45773101e-02,\n",
              "          2.89088130e-01, -2.43632138e-01, -1.48099631e-01,\n",
              "          3.65899026e-01, -2.65855312e-01,  2.38331631e-01,\n",
              "         -1.07373158e-02, -1.92865849e-01, -5.04798107e-02,\n",
              "         -1.19904213e-01,  1.83370471e-01, -2.75247116e-02,\n",
              "         -6.37372807e-02, -2.86384672e-01, -2.84130633e-01,\n",
              "          1.09409057e-01,  1.64182559e-01, -1.81838080e-01,\n",
              "         -2.88007855e-02,  2.77605355e-01,  5.05335117e-03,\n",
              "          6.89942539e-02, -7.10197389e-02, -7.96662457e-03,\n",
              "         -1.12805609e-02,  1.34263337e-01],\n",
              "        [-1.36422343e-03,  8.04358721e-02, -3.02946627e-01,\n",
              "         -2.90917791e-02,  1.88380759e-02,  2.15618238e-01,\n",
              "         -1.93901271e-01,  2.46789515e-01, -3.05424005e-01,\n",
              "         -2.99663637e-02, -3.06702733e-01, -2.20616266e-01,\n",
              "          1.97099924e-01,  2.59047329e-01, -2.20441893e-02,\n",
              "         -1.84846427e-02, -1.45109922e-01,  2.70052701e-01,\n",
              "         -3.29650700e-01, -1.81086913e-01,  3.20313901e-01,\n",
              "          3.83949839e-02,  2.59743445e-02, -5.10559268e-02,\n",
              "          3.85505296e-02, -3.48987997e-01, -3.30340937e-02,\n",
              "          9.94597673e-02,  2.45278314e-01,  2.26400807e-01,\n",
              "          8.80463645e-02,  1.36521608e-01],\n",
              "        [ 2.00432733e-01,  1.57177038e-02, -9.04026330e-02,\n",
              "          3.41987275e-02, -3.04095209e-01,  2.71453768e-01,\n",
              "         -2.80827731e-01, -2.33713970e-01, -1.93269804e-01,\n",
              "         -1.52194783e-01,  2.61635840e-01, -2.04049200e-01,\n",
              "          1.36748657e-01, -1.11640446e-01,  1.67805910e-01,\n",
              "         -2.13704616e-01, -1.04255930e-01,  1.88223366e-03,\n",
              "         -5.65852486e-02, -3.49306092e-02,  2.94741005e-01,\n",
              "          1.79809988e-01, -6.59547895e-02, -1.09174691e-01,\n",
              "         -9.40047652e-02,  1.96272314e-01, -1.86789464e-02,\n",
              "         -2.91734487e-01, -2.29460523e-01,  2.36332193e-01,\n",
              "          3.10090333e-01, -9.39506944e-03],\n",
              "        [ 1.60097986e-01,  4.22602752e-04,  2.21356347e-01,\n",
              "          1.23819329e-01, -1.15492538e-01,  2.00121418e-01,\n",
              "          2.52987176e-01, -2.95203626e-01, -2.18853280e-01,\n",
              "         -2.04330608e-01,  1.00931250e-01,  2.98592616e-02,\n",
              "         -2.14776187e-03, -2.54923552e-01, -1.69978535e-03,\n",
              "          1.26703344e-02,  2.69241482e-01, -2.85368055e-01,\n",
              "          1.86358407e-01,  1.89162523e-01, -1.37986660e-01,\n",
              "          3.22741687e-01,  2.90067434e-01,  2.67198473e-01,\n",
              "          9.52518359e-02, -2.64042497e-01, -1.30239889e-01,\n",
              "          7.11316466e-02,  2.83580661e-01, -2.95748919e-01,\n",
              "          4.11587618e-02, -7.58138970e-02],\n",
              "        [-2.15895340e-01,  3.02253515e-01, -1.18767649e-01,\n",
              "          2.50213325e-01, -1.93269536e-01, -2.87697762e-01,\n",
              "         -3.18181403e-02,  8.74144286e-02, -2.48137936e-01,\n",
              "          7.69842714e-02, -3.20056021e-01, -3.37691963e-01,\n",
              "         -3.11312247e-02,  3.22973311e-01,  2.87356284e-02,\n",
              "          3.67479116e-01,  2.11769149e-01, -2.65497267e-01,\n",
              "         -7.41007701e-02,  9.96831879e-02, -3.45341593e-01,\n",
              "          7.44693354e-02,  7.79487863e-02, -1.48882329e-01,\n",
              "          3.02764714e-01,  1.67029724e-01, -1.99833408e-01,\n",
              "          1.34742204e-02, -2.06820160e-01, -1.69625774e-01,\n",
              "         -1.82900533e-01,  1.95088431e-01],\n",
              "        [-1.51213303e-01, -2.44972035e-01, -5.56568429e-02,\n",
              "         -2.21701507e-02,  2.28326857e-01, -1.53946474e-01,\n",
              "         -1.97404042e-01,  9.91898552e-02, -2.48285562e-01,\n",
              "         -2.58851320e-01,  1.88155726e-01,  2.13771239e-01,\n",
              "          3.38160485e-01,  3.07953060e-01, -3.13889682e-01,\n",
              "         -2.09863439e-01, -2.62790203e-01,  2.94106841e-01,\n",
              "          1.41480654e-01,  3.04210652e-02,  1.05245337e-02,\n",
              "         -1.31625444e-01, -1.17706880e-01,  4.45516892e-02,\n",
              "         -4.42963578e-02,  2.16395810e-01,  2.56715745e-01,\n",
              "         -2.60140508e-01,  3.28434497e-01, -8.44937097e-03,\n",
              "          2.87340563e-02,  1.78792372e-01]], dtype=float32),\n",
              " array([-8.60669170e-05, -6.09682647e-05,  7.57411326e-05, -7.21582328e-05,\n",
              "        -1.29833279e-04, -2.53504462e-04, -5.72693716e-05,  1.23211314e-04,\n",
              "         3.68217501e-04, -1.96337656e-04,  2.24725427e-05,  3.59121768e-05,\n",
              "         1.15306844e-04,  3.10613686e-04,  1.00403049e-04, -1.99111018e-04,\n",
              "         1.68003644e-05, -1.18160351e-04,  6.00256666e-04,  9.03458786e-05,\n",
              "        -5.02795847e-05, -1.76544490e-04,  1.21861987e-04,  4.12176159e-05,\n",
              "        -6.76387062e-05, -2.30043297e-04, -3.84139930e-05,  3.16959170e-09,\n",
              "         2.80617242e-05, -3.71310489e-05, -5.65978640e-04, -2.44474446e-04],\n",
              "       dtype=float32),\n",
              " array([[-0.19091137,  0.29256937, -0.03992933, -0.11280819,  0.00970167,\n",
              "          0.03536592,  0.16450259, -0.20344898,  0.20957355,  0.12522547,\n",
              "          0.1819694 ,  0.2895442 , -0.29990882,  0.17902535, -0.3176409 ,\n",
              "         -0.12474563,  0.20863168,  0.1468624 ,  0.2764907 , -0.23575397],\n",
              "        [-0.3329889 , -0.07022779,  0.16937962,  0.09158894,  0.19050458,\n",
              "          0.20331845, -0.10732608, -0.2919393 ,  0.21801297, -0.01293941,\n",
              "          0.11103517,  0.21931367, -0.29686645, -0.3294651 , -0.01141732,\n",
              "          0.21513367,  0.16373336,  0.2705021 ,  0.09157171,  0.31213954],\n",
              "        [-0.06473102, -0.08340833, -0.27000925, -0.24598491, -0.3318708 ,\n",
              "         -0.22199766,  0.06761792,  0.02080037,  0.10241333,  0.16131188,\n",
              "         -0.25891432, -0.09917922,  0.24360423, -0.30682543, -0.1469116 ,\n",
              "         -0.15101904, -0.11771321, -0.1508086 , -0.34299138,  0.02722153],\n",
              "        [-0.00727295, -0.1972846 , -0.1385113 ,  0.2589296 , -0.31963858,\n",
              "         -0.03123055,  0.25843906,  0.3393596 , -0.00347652, -0.21362105,\n",
              "          0.00551812,  0.18878826,  0.17158896,  0.03743544,  0.05124452,\n",
              "         -0.22642688, -0.0011539 , -0.01212942, -0.13116768,  0.20612425],\n",
              "        [ 0.06751319, -0.33859086, -0.32882956, -0.14300586, -0.10411233,\n",
              "         -0.11674074, -0.05026422, -0.27350456,  0.19114843,  0.2610682 ,\n",
              "         -0.14385915,  0.11433321, -0.2678915 ,  0.30790734, -0.19780293,\n",
              "         -0.13950469,  0.04629946, -0.17289928,  0.05525915, -0.15555885],\n",
              "        [-0.17488894, -0.17912142,  0.21015702,  0.19617803, -0.15728287,\n",
              "          0.09376037, -0.11092924, -0.19617307,  0.3115143 ,  0.21889472,\n",
              "          0.34973475, -0.33129582, -0.01886709, -0.05938626, -0.12593056,\n",
              "         -0.08705053,  0.23618846, -0.07457035,  0.28856707,  0.2654338 ],\n",
              "        [-0.30622956, -0.11543592,  0.04186742, -0.15454544,  0.30582786,\n",
              "         -0.28887057,  0.05428331, -0.3311528 ,  0.26221025, -0.22115171,\n",
              "          0.31438872,  0.07227447,  0.02025732,  0.21576132,  0.04560333,\n",
              "         -0.21922699, -0.14032926,  0.1937171 , -0.21587266, -0.23856653],\n",
              "        [-0.32690418,  0.11130601, -0.1746525 ,  0.03533379,  0.06776246,\n",
              "          0.19104777,  0.2842187 ,  0.12132686,  0.2540484 , -0.30713722,\n",
              "          0.04683599, -0.13964675,  0.31426588, -0.17228977, -0.18956734,\n",
              "          0.21009162, -0.14994359, -0.02154084,  0.34735   , -0.12733169],\n",
              "        [-0.18786688,  0.22638457, -0.3239558 , -0.27876034, -0.30414486,\n",
              "         -0.10063011, -0.31170902, -0.27277735,  0.12613425,  0.21297678,\n",
              "          0.00852312, -0.14057584,  0.22743483,  0.00594292,  0.34853315,\n",
              "          0.15905291,  0.19196706,  0.15963286, -0.06942137, -0.13401979],\n",
              "        [ 0.22945721,  0.04292198, -0.13329351,  0.32818216,  0.3174101 ,\n",
              "          0.30829605,  0.06841654,  0.16892213, -0.17435502,  0.15467244,\n",
              "          0.05910223, -0.22025976,  0.29682085,  0.24233986, -0.00503904,\n",
              "          0.04751058, -0.08699472,  0.33132178,  0.26139733,  0.28693575],\n",
              "        [-0.14306982, -0.24408817, -0.07183982,  0.05246039,  0.10768963,\n",
              "          0.05557347, -0.05617848, -0.29575852, -0.28030923, -0.28208828,\n",
              "         -0.13292074,  0.1934981 ,  0.14828224,  0.3129928 , -0.16450651,\n",
              "          0.1304941 ,  0.17255183, -0.35077432, -0.1643409 ,  0.16602053],\n",
              "        [ 0.07500611,  0.16468038,  0.3168247 ,  0.3125535 ,  0.1100039 ,\n",
              "          0.06197846, -0.33269718,  0.0979763 , -0.2698601 ,  0.03703251,\n",
              "         -0.15126896,  0.31810787,  0.27085382,  0.264181  ,  0.1334606 ,\n",
              "         -0.3308484 , -0.32867032, -0.04275992, -0.23219422,  0.26401103],\n",
              "        [-0.10499386,  0.17352456,  0.02605671,  0.02108783,  0.27319437,\n",
              "          0.24610662, -0.21543935, -0.1736219 , -0.07979653, -0.2822503 ,\n",
              "         -0.28367665,  0.20831735, -0.26417604, -0.30954137,  0.24608523,\n",
              "         -0.17017789, -0.20166436,  0.23910752,  0.02931633, -0.02721626],\n",
              "        [ 0.2478401 ,  0.32527912,  0.09592739,  0.04587046, -0.30320972,\n",
              "          0.26378483,  0.07415096,  0.03458274,  0.33387008, -0.24881338,\n",
              "          0.10742307,  0.19417644,  0.19035119, -0.27132228,  0.11974221,\n",
              "          0.05178064, -0.01295877, -0.24071151, -0.07351276,  0.19430642],\n",
              "        [ 0.24196549,  0.04945777,  0.24265705,  0.12608775,  0.06220476,\n",
              "         -0.02990728,  0.25398576, -0.0335159 ,  0.11900198, -0.06137589,\n",
              "          0.24107781,  0.19005843, -0.26256108, -0.28045496, -0.0320369 ,\n",
              "         -0.01395829,  0.18413253, -0.02388057, -0.04564327, -0.06603042],\n",
              "        [ 0.27136254,  0.28194588, -0.29367977,  0.291912  , -0.03311992,\n",
              "         -0.37943375,  0.10462796,  0.30831522, -0.2694262 , -0.07627171,\n",
              "         -0.04562503, -0.02713392,  0.00937065, -0.16685706, -0.06344955,\n",
              "         -0.20693766, -0.09073276,  0.21723953, -0.18091738,  0.11571227],\n",
              "        [ 0.32091916,  0.10919789, -0.20212056, -0.11971585,  0.23381448,\n",
              "         -0.00945306,  0.1445816 , -0.22850165, -0.10254236, -0.34859928,\n",
              "          0.08884521, -0.00120452, -0.2998297 , -0.17094767,  0.17889376,\n",
              "          0.19039865,  0.01964448,  0.22436152,  0.21626717,  0.11215157],\n",
              "        [-0.28106263, -0.22742653, -0.21959046,  0.3053132 , -0.27925354,\n",
              "         -0.04684147,  0.2995244 ,  0.28835508, -0.14815748, -0.19502598,\n",
              "         -0.09352625,  0.09703249,  0.16558623,  0.18581398,  0.02553465,\n",
              "          0.0653891 , -0.00196183,  0.26616886, -0.18255141,  0.19486368],\n",
              "        [-0.27872825,  0.2584428 , -0.02180092,  0.28107646, -0.31955287,\n",
              "          0.02106616, -0.34281403,  0.26912376,  0.15262143,  0.29571632,\n",
              "         -0.23164064,  0.01877444, -0.3146228 ,  0.2000994 ,  0.11148187,\n",
              "          0.12381887, -0.19681023,  0.31173986, -0.11852052, -0.18038864],\n",
              "        [-0.20280896, -0.08197236, -0.12192142,  0.1214286 , -0.03737765,\n",
              "         -0.08431915,  0.18281265,  0.15072235,  0.12545244, -0.0418762 ,\n",
              "         -0.22387622,  0.31046903, -0.33196762,  0.09329762,  0.2465363 ,\n",
              "          0.03138791, -0.08767494,  0.13579303, -0.33470863, -0.18831   ],\n",
              "        [-0.08496947, -0.03641429, -0.03682904, -0.16127193, -0.2147202 ,\n",
              "          0.03131413,  0.03678969, -0.24066578,  0.17403714, -0.06360579,\n",
              "          0.2515663 , -0.052153  ,  0.14384177,  0.07012537,  0.00768053,\n",
              "          0.2413616 , -0.31927046, -0.25328082,  0.28109646, -0.03675229],\n",
              "        [ 0.09557753, -0.17050281, -0.00250726, -0.17589362,  0.33940998,\n",
              "         -0.01347831, -0.09179512,  0.13438247,  0.15207654,  0.27013674,\n",
              "          0.1198277 ,  0.11622854,  0.05323427,  0.03313651,  0.13592726,\n",
              "          0.03472983, -0.23206726, -0.30184028,  0.302187  ,  0.10480803],\n",
              "        [-0.22728348,  0.24327837, -0.13174985, -0.04887836,  0.23138967,\n",
              "          0.21501558, -0.09372059,  0.0458715 ,  0.2568487 , -0.02037267,\n",
              "         -0.09935226,  0.00922438, -0.28250515, -0.1371555 ,  0.30542728,\n",
              "          0.20853283,  0.3102331 ,  0.3178084 ,  0.06979673,  0.08238379],\n",
              "        [ 0.1549346 ,  0.05501601,  0.18543759,  0.18582976, -0.1289416 ,\n",
              "         -0.282391  ,  0.01611622,  0.07866956, -0.21294965, -0.13992481,\n",
              "         -0.10020854,  0.16111003, -0.1797973 , -0.03754929,  0.18934694,\n",
              "         -0.08016673,  0.05516886,  0.02640687,  0.13764101,  0.10273705],\n",
              "        [ 0.13630733,  0.00121982, -0.21072383, -0.13119505,  0.24659504,\n",
              "         -0.02005621,  0.17412254, -0.00775489,  0.0760643 ,  0.05292027,\n",
              "          0.038808  ,  0.30160022,  0.28319353, -0.33198193,  0.00067131,\n",
              "          0.33834374,  0.24308413, -0.00449432, -0.10512846, -0.12231454],\n",
              "        [ 0.22357191, -0.00051596,  0.04883548, -0.12792271, -0.2611843 ,\n",
              "          0.25635797, -0.17239052, -0.09243501, -0.27428973, -0.31554464,\n",
              "         -0.2571276 , -0.18997616,  0.12772049, -0.10475065, -0.14810339,\n",
              "          0.14776976, -0.27644008, -0.23143876, -0.28726557, -0.1332826 ],\n",
              "        [-0.16401021, -0.2329021 , -0.0975272 , -0.19121812,  0.27201378,\n",
              "         -0.0758514 , -0.09656863,  0.33244044,  0.16895577, -0.20874609,\n",
              "          0.10660123,  0.3159118 ,  0.15750915,  0.1063241 , -0.04526998,\n",
              "          0.15273206, -0.12487563, -0.07625643, -0.0957159 ,  0.28740066],\n",
              "        [ 0.10010239,  0.2337107 , -0.25473958,  0.09053859, -0.29246435,\n",
              "         -0.3368506 ,  0.22266358,  0.06615987, -0.15686886,  0.27248913,\n",
              "         -0.12294844, -0.11113653,  0.08718038, -0.1642738 ,  0.1184732 ,\n",
              "          0.26092577, -0.1880631 ,  0.32636625, -0.05599126,  0.19385529],\n",
              "        [-0.04274514,  0.16946663, -0.26760542,  0.26813182,  0.25138018,\n",
              "         -0.24965023, -0.11987785, -0.01517417, -0.02678309, -0.18990089,\n",
              "          0.13959497, -0.28824487,  0.3036499 ,  0.07566737,  0.03756714,\n",
              "          0.33059737,  0.1137728 ,  0.24287651,  0.22618422,  0.00950934],\n",
              "        [-0.18649581, -0.03773928, -0.21738476,  0.1404454 ,  0.14989005,\n",
              "          0.19937848, -0.02480297, -0.26551926,  0.07538598,  0.14140175,\n",
              "          0.05731607, -0.15567337,  0.02336041, -0.08715468,  0.23852144,\n",
              "         -0.02323815, -0.3149122 , -0.2895068 ,  0.02817782, -0.3038634 ],\n",
              "        [-0.30448738, -0.09758607,  0.14161089,  0.2593382 ,  0.16884321,\n",
              "          0.08603534, -0.1353187 , -0.0311067 , -0.28970376, -0.16947871,\n",
              "          0.16659606,  0.03118277,  0.3214515 , -0.10747386, -0.31418347,\n",
              "         -0.01689061,  0.29745227, -0.32261953,  0.10340261,  0.28776386],\n",
              "        [-0.2373304 ,  0.14547838, -0.01384353,  0.20298977,  0.08126646,\n",
              "         -0.06950778,  0.19825242, -0.25332013, -0.15316698,  0.04930064,\n",
              "          0.16344208,  0.29534578,  0.2035767 , -0.2980964 , -0.10565118,\n",
              "          0.07914891,  0.34477106, -0.1967162 ,  0.2201275 , -0.03649561]],\n",
              "       dtype=float32),\n",
              " array([ 0.00439003, -0.00984381,  0.00283802,  0.00436466, -0.01178993,\n",
              "        -0.01254337, -0.00543498,  0.00805475,  0.00397123, -0.01038993,\n",
              "        -0.00251463, -0.00404484, -0.0257544 ,  0.00651152, -0.01334499,\n",
              "         0.00672723, -0.00322138,  0.00399829, -0.00390133,  0.00145532],\n",
              "       dtype=float32),\n",
              " array([[-0.16953371],\n",
              "        [-0.46688974],\n",
              "        [ 0.31641567],\n",
              "        [-0.08556533],\n",
              "        [ 0.4663295 ],\n",
              "        [ 0.2828374 ],\n",
              "        [ 0.23503046],\n",
              "        [-0.23539856],\n",
              "        [-0.27217346],\n",
              "        [ 0.18411309],\n",
              "        [ 0.24618997],\n",
              "        [ 0.13780616],\n",
              "        [ 0.5509503 ],\n",
              "        [ 0.33238885],\n",
              "        [-0.5824375 ],\n",
              "        [-0.14686233],\n",
              "        [ 0.14899261],\n",
              "        [-0.3243098 ],\n",
              "        [ 0.38166   ],\n",
              "        [-0.04831651]], dtype=float32),\n",
              " array([-0.1037232], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWrM5NSo-RcB",
        "colab_type": "code",
        "outputId": "30b2c232-45ac-4877-edc5-67b001977312",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.evaluate(xtest, ytest)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "250/250 [==============================] - 0s 210us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7054114632606506, 0.4720000011920929]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COddy5Ar-wUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
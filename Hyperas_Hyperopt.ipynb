{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hyperas_Hyperopt.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohanBrid18/ML-Workshop/blob/master/Hyperas_Hyperopt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYdi32_ixNJY",
        "colab_type": "code",
        "outputId": "a44daf21-744f-4ca5-bf42-401f44492e9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install hyperas\n",
        "!pip install hyperopt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hyperas\n",
            "  Downloading https://files.pythonhosted.org/packages/04/34/87ad6ffb42df9c1fa9c4c906f65813d42ad70d68c66af4ffff048c228cd4/hyperas-0.4.1-py3-none-any.whl\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from hyperas) (0.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from hyperas) (4.4.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from hyperas) (5.5.0)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from hyperas) (1.0.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from hyperas) (2.2.4)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (from hyperas) (0.1.2)\n",
            "Requirement already satisfied: traitlets>=4.1 in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (4.3.2)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (2.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (4.4.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.6.0)\n",
            "Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.8.4)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (2.1.3)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (2.10.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (3.1.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.4.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (1.4.2)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (7.4.2)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (4.6.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (6.0.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (5.2.2)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (4.5.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (2.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.16.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (4.28.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (0.16.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (3.8.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (2.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1->nbformat->hyperas) (4.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert->hyperas) (1.1.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->hyperas) (0.5.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.4.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->hyperas) (3.4.2)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->hyperas) (5.5.0)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->hyperas) (4.5.3)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->hyperas) (5.2.4)\n",
            "Collecting prompt-toolkit<2.1.0,>=2.0.0 (from jupyter-console->jupyter->hyperas)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/a7/9b1dd14ef45345f186ef69d175bdd2491c40ab1dfa4b2b3e4352df719ed7/prompt_toolkit-2.0.9-py3-none-any.whl (337kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (0.8.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (41.0.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (4.7.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (0.7.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->jupyter->hyperas) (2.5.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->jupyter->hyperas) (17.0.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->jupyter-console->jupyter->hyperas) (0.1.7)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->jupyter->hyperas) (0.6.0)\n",
            "\u001b[31mERROR: ipython 5.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.4, but you'll have prompt-toolkit 2.0.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: hyperas, prompt-toolkit\n",
            "  Found existing installation: prompt-toolkit 1.0.16\n",
            "    Uninstalling prompt-toolkit-1.0.16:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.16\n",
            "Successfully installed hyperas-0.4.1 prompt-toolkit-2.0.9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "prompt_toolkit"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (0.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.3.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt) (3.8.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt) (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from hyperopt) (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.16.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt) (2.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.12.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt) (4.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3rEszUh5TuI",
        "colab_type": "code",
        "outputId": "80c03ae3-ed2f-4dfb-a71e-c9cb3636a819",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "from hyperopt import Trials, STATUS_OK, tpe\n",
        "from hyperas import optim\n",
        "from hyperas.distributions import choice, uniform\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdFjtmrj5Gfz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data():\n",
        "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "    X_train = X_train.reshape(60000, 784)\n",
        "    X_test = X_test.reshape(10000, 784)\n",
        "    X_train = X_train.astype('float32')\n",
        "    X_test = X_test.astype('float32')\n",
        "    X_train /= 255\n",
        "    X_test /= 255\n",
        "    nb_classes = 10\n",
        "    Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "    Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
        "    return X_train, Y_train, X_test, Y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIygRZ6f5UkF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(X_train, Y_train, X_test, Y_test):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(512, input_shape=(784,)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout({{uniform(0, 1)}}))\n",
        "    model.add(Dense({{choice([256, 512, 1024])}}))\n",
        "    model.add(Activation({{choice(['relu', 'sigmoid'])}}))\n",
        "    model.add(Dropout({{uniform(0, 1)}}))\n",
        "\n",
        "    # If we choose 'four', add an additional fourth layer\n",
        "    if {{choice(['three', 'four'])}} == 'four':\n",
        "        model.add(Dense(100))\n",
        "        model.add({{choice([Dropout(0.5), Activation('linear')])}})\n",
        "        model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Dense(10))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer={{choice(['rmsprop', 'adam', 'sgd'])}},\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.fit(X_train, Y_train,\n",
        "              batch_size={{choice([64, 128])}},\n",
        "              epochs=1,\n",
        "              verbose=2,\n",
        "              validation_data=(X_test, Y_test))\n",
        "    score, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
        "    print('Test accuracy:', acc)\n",
        "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjlatkWq5Wab",
        "colab_type": "code",
        "outputId": "6235f07c-f11c-4e0b-a387-ede66d5223c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Copy/download the file\n",
        "fid = drive.ListFile({'q':\"title='Hyperas_Hyperopt_Example.ipynb'\"}).GetList()[0]['id']\n",
        "f = drive.CreateFile({'id': fid})\n",
        "f.GetContentFile('Hyperas_Hyperopt_Example.ipynb')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 17.3MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 1.8MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 2.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 2.9MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 2.9MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 2.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 624kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 634kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 655kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 665kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 686kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 696kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 716kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 727kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 747kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 757kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 2.9MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0626 15:46:34.790133 140118457145216 __init__.py:44] file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 36, in autodetect\n",
            "    from google.appengine.api import memcache\n",
            "ModuleNotFoundError: No module named 'google.appengine'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 41, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    'file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth')\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdo3mScvBHF4",
        "colab_type": "code",
        "outputId": "e781d402-b488-4be4-a00c-829cf7bf51ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "best_run, best_model = optim.minimize(model=model,\n",
        "                                          data=data,\n",
        "                                          max_evals=10,\n",
        "                                          algo=tpe.suggest,\n",
        "                                          notebook_name='Hyperas_Hyperopt_Example',\n",
        "                                          trials=Trials()\n",
        "                                     )"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> Imports:\n",
            "#coding=utf-8\n",
            "\n",
            "from __future__ import print_function\n",
            "\n",
            "try:\n",
            "    from hyperopt import Trials, STATUS_OK, tpe\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas import optim\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas.distributions import choice, uniform\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.models import Sequential\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers.core import Dense, Dropout, Activation\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.datasets import mnist\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.utils import np_utils\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from pydrive.auth import GoogleAuth\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from pydrive.drive import GoogleDrive\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from google.colab import auth\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from oauth2client.client import GoogleCredentials\n",
            "except:\n",
            "    pass\n",
            "\n",
            ">>> Hyperas search space:\n",
            "\n",
            "def get_space():\n",
            "    return {\n",
            "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
            "        'Dense': hp.choice('Dense', [256, 512, 1024]),\n",
            "        'Activation': hp.choice('Activation', ['relu', 'sigmoid']),\n",
            "        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\n",
            "        'Dropout_2': hp.choice('Dropout_2', ['three', 'four']),\n",
            "        'add': hp.choice('add', [Dropout(0.5), Activation('linear')]),\n",
            "        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd']),\n",
            "        'batch_size': hp.choice('batch_size', [64, 128]),\n",
            "    }\n",
            "\n",
            ">>> Data\n",
            "  1: \n",
            "  2: '''\n",
            "  3: Data providing function:\n",
            "  4: This function is separated from model() so that hyperopt\n",
            "  5: won't reload data for each evaluation run.\n",
            "  6: '''\n",
            "  7: (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
            "  8: X_train = X_train.reshape(60000, 784)\n",
            "  9: X_test = X_test.reshape(10000, 784)\n",
            " 10: X_train = X_train.astype('float32')\n",
            " 11: X_test = X_test.astype('float32')\n",
            " 12: X_train /= 255\n",
            " 13: X_test /= 255\n",
            " 14: nb_classes = 10\n",
            " 15: Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
            " 16: Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
            " 17: \n",
            " 18: \n",
            " 19: \n",
            ">>> Resulting replaced keras model:\n",
            "\n",
            "   1: def keras_fmin_fnct(space):\n",
            "   2: \n",
            "   3:     '''\n",
            "   4:     Model providing function:\n",
            "   5:     Create Keras model with double curly brackets dropped-in as needed.\n",
            "   6:     Return value has to be a valid python dictionary with two customary keys:\n",
            "   7:         - loss: Specify a numeric evaluation metric to be minimized\n",
            "   8:         - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
            "   9:     The last one is optional, though recommended, namely:\n",
            "  10:         - model: specify the model just created so that we can later use it again.\n",
            "  11:     '''\n",
            "  12:     model = Sequential()\n",
            "  13:     model.add(Dense(512, input_shape=(784,)))\n",
            "  14:     model.add(Activation('relu'))\n",
            "  15:     model.add(Dropout(space['Dropout']))\n",
            "  16:     model.add(Dense(space['Dense']))\n",
            "  17:     model.add(Activation(space['Activation']))\n",
            "  18:     model.add(Dropout(space['Dropout_1']))\n",
            "  19: \n",
            "  20:     # If we choose 'four', add an additional fourth layer\n",
            "  21:     if space['Dropout_2'] == 'four':\n",
            "  22:         model.add(Dense(100))\n",
            "  23:         model.add(space['add'])\n",
            "  24:         model.add(Activation('relu'))\n",
            "  25: \n",
            "  26:     model.add(Dense(10))\n",
            "  27:     model.add(Activation('softmax'))\n",
            "  28: \n",
            "  29:     model.compile(loss='categorical_crossentropy',\n",
            "  30:                   optimizer=space['optimizer'],\n",
            "  31:                   metrics=['accuracy'])\n",
            "  32: \n",
            "  33:     model.fit(X_train, Y_train,\n",
            "  34:               batch_size=space['batch_size'],\n",
            "  35:               epochs=1,\n",
            "  36:               verbose=2,\n",
            "  37:               validation_data=(X_test, Y_test))\n",
            "  38:     score, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
            "  39:     print('Test accuracy:', acc)\n",
            "  40:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
            "  41: \n",
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0626 15:47:13.696352 140118457145216 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0626 15:47:13.743295 140118457145216 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0626 15:47:13.751459 140118457145216 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0626 15:47:13.769048 140118457145216 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0626 15:47:13.778276 140118457145216 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0626 15:47:13.779275 140118457145216 nn_ops.py:4224] Large dropout rate: 0.610876 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "W0626 15:47:13.815706 140118457145216 nn_ops.py:4224] Large dropout rate: 0.73717 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "W0626 15:47:13.847591 140118457145216 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0626 15:47:13.872361 140118457145216 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0626 15:47:13.984388 140118457145216 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 5s - loss: 1.6568 - acc: 0.4452 - val_loss: 0.7669 - val_acc: 0.8297\n",
            "\n",
            "Test accuracy:\n",
            "0.8297\n",
            " 10%|█         | 1/10 [00:05<00:51,  5.75s/it, best loss: -0.8297]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0626 15:47:19.520838 140118457145216 nn_ops.py:4224] Large dropout rate: 0.977001 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "W0626 15:47:19.551698 140118457145216 nn_ops.py:4224] Large dropout rate: 0.836667 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 3s - loss: 2.1507 - acc: 0.2982 - val_loss: 0.7133 - val_acc: 0.7897\n",
            "\n",
            "Test accuracy:\n",
            "0.7897\n",
            " 20%|██        | 2/10 [00:09<00:41,  5.23s/it, best loss: -0.8297]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0626 15:47:23.545109 140118457145216 nn_ops.py:4224] Large dropout rate: 0.975819 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 3s - loss: 1.9204 - acc: 0.3131 - val_loss: 0.6935 - val_acc: 0.8820\n",
            "\n",
            "Test accuracy:\n",
            "0.882\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 2s - loss: 0.7232 - acc: 0.7691 - val_loss: 0.2010 - val_acc: 0.9393\n",
            "\n",
            "Test accuracy:\n",
            "0.9393\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 2s - loss: 0.5299 - acc: 0.8360 - val_loss: 0.1702 - val_acc: 0.9503\n",
            "\n",
            "Test accuracy:\n",
            "0.9503\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 2s - loss: 2.6957 - acc: 0.1107 - val_loss: 2.1501 - val_acc: 0.5375\n",
            "\n",
            "Test accuracy:\n",
            "0.5375\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 2s - loss: 0.2794 - acc: 0.9128 - val_loss: 0.1177 - val_acc: 0.9632\n",
            "\n",
            "Test accuracy:\n",
            "0.9632\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 2s - loss: 2.2490 - acc: 0.1723 - val_loss: 2.0616 - val_acc: 0.4356\n",
            "\n",
            "Test accuracy:\n",
            "0.4356\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 2s - loss: 0.4585 - acc: 0.8528 - val_loss: 0.1863 - val_acc: 0.9434\n",
            "\n",
            "Test accuracy:\n",
            "0.9434\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 4s - loss: 0.2930 - acc: 0.9089 - val_loss: 0.1344 - val_acc: 0.9578\n",
            "\n",
            "Test accuracy:\n",
            "0.9578\n",
            "100%|██████████| 10/10 [00:36<00:00,  3.81s/it, best loss: -0.9632]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1B1URGwDd_gu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "771b8631-dae1-4682-d957-104b94d3425d"
      },
      "source": [
        "best_model"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7f6f3674acf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zorIUfzPejl2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "a5a61c0c-74af-4013-dfba-b9d93e3a4ec8"
      },
      "source": [
        "best_run"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Activation': 0,\n",
              " 'Dense': 1,\n",
              " 'Dropout': 0.2283813112902432,\n",
              " 'Dropout_1': 0.5422412690636627,\n",
              " 'Dropout_2': 0,\n",
              " 'add': 0,\n",
              " 'batch_size': 1,\n",
              " 'optimizer': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ji7bjSZseoy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}